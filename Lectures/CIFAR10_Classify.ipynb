{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.layers import Input, Conv2D, LeakyReLU, GlobalAveragePooling2D, Dense, Dropout, Softmax\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "epochs = 12\n",
    "batch_size = 128\n",
    "depth = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ds, info = tfds.load(\"cifar10\", split='train', with_info=True, shuffle_files=True, download=True)\n",
    "total_images = info.splits['train'].num_examples\n",
    "total_batches = total_images//batch_size\n",
    "total_steps = total_batches * epochs\n",
    "xSize, ySize, rgbSize = info.features['image'].shape\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_mean = tf.constant([[[0.49139968, 0.48215841, 0.44653091]]])\n",
    "image_std = tf.constant([[[0.24703223, 0.24348513, 0.26158784]]])\n",
    "def normalize(item):\n",
    "    \"\"\"\n",
    "    Normalize the images\n",
    "    \"\"\"\n",
    "    image = tf.cast(item['image'], tf.float32) / 255.0\n",
    "    image = (image - image_mean) / image_std # zero mean unit variance\n",
    "    label = item['label'] #use to_categorical for CategoricalCrossEntropy\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.shuffle(total_images)\n",
    "train_ds = train_ds.map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ConvNet\"\n",
      "_____________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                              Output Shape                                          Param #             \n",
      "=====================================================================================================================================\n",
      " ConvNetinput (InputLayer)                                 [(None, 32, 32, 3)]                                   0                   \n",
      "                                                                                                                                     \n",
      " conv2d (Conv2D)                                           (None, 32, 32, 64)                                    1792                \n",
      "                                                                                                                                     \n",
      " conv2d_1 (Conv2D)                                         (None, 16, 16, 64)                                    36928               \n",
      "                                                                                                                                     \n",
      " conv2d_2 (Conv2D)                                         (None, 16, 16, 128)                                   73856               \n",
      "                                                                                                                                     \n",
      " conv2d_3 (Conv2D)                                         (None, 8, 8, 128)                                     147584              \n",
      "                                                                                                                                     \n",
      " conv2d_4 (Conv2D)                                         (None, 8, 8, 256)                                     295168              \n",
      "                                                                                                                                     \n",
      " conv2d_5 (Conv2D)                                         (None, 4, 4, 256)                                     590080              \n",
      "                                                                                                                                     \n",
      " conv2d_6 (Conv2D)                                         (None, 4, 4, 512)                                     1180160             \n",
      "                                                                                                                                     \n",
      " global_average_pooling2d (GlobalAveragePooling2D)         (None, 512)                                           0                   \n",
      "                                                                                                                                     \n",
      " dense (Dense)                                             (None, 256)                                           131328              \n",
      "                                                                                                                                     \n",
      " dense_1 (Dense)                                           (None, 128)                                           32896               \n",
      "                                                                                                                                     \n",
      " dense_2 (Dense)                                           (None, 10)                                            1290                \n",
      "                                                                                                                                     \n",
      "=====================================================================================================================================\n",
      "Total params: 2,491,082\n",
      "Trainable params: 2,491,082\n",
      "Non-trainable params: 0\n",
      "_____________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "kernel = 3\n",
    "input_shape =(xSize, ySize, rgbSize)\n",
    "\n",
    "#architecture\n",
    "def encoder_network(input_shape, activation, name=\"E\"):\n",
    "    \"\"\"\n",
    "    Encodes images into latent space\n",
    "    \"\"\"\n",
    "    input = Input(input_shape, name=name+\"input\")\n",
    "    net = Conv2D(depth, kernel_size=kernel, padding='same', activation=LeakyReLU(alpha=0.1))(input)\n",
    "    net = Conv2D(depth, kernel_size=kernel, padding='same', activation=LeakyReLU(alpha=0.1), strides=2)(net)\n",
    "    net = Conv2D(depth*2, kernel_size=kernel, padding='same', activation=LeakyReLU(alpha=0.1))(net)\n",
    "    net = Conv2D(depth*2, kernel_size=kernel, padding='same', activation=LeakyReLU(alpha=0.1), strides=2)(net)\n",
    "    net = Conv2D(depth*4, kernel_size=kernel, padding='same', activation=LeakyReLU(alpha=0.1))(net)\n",
    "    net = Conv2D(depth*4, kernel_size=kernel, padding='same', activation=LeakyReLU(alpha=0.1), strides=2)(net)\n",
    "    net = Conv2D(depth*8, kernel_size=kernel, padding='same', activation=LeakyReLU(alpha=0.1))(net)\n",
    "    dense = GlobalAveragePooling2D()(net)\n",
    "    # dense=Dropout(rate=0.5)(dense)\n",
    "    dense = Dense(256, activation=LeakyReLU(alpha=0.1), kernel_initializer = tf.keras.initializers.glorot_normal())(dense)\n",
    "    #dense=Dropout(rate=0.5)(dense)\n",
    "    dense = Dense(128, activation=LeakyReLU(alpha=0.1), kernel_initializer = tf.keras.initializers.glorot_normal())(dense)\n",
    "    #dense=Dropout(rate=0.5)(dense)\n",
    "    latent = Dense(num_classes, kernel_initializer = tf.keras.initializers.glorot_normal(), activation=activation)(dense)\n",
    "\n",
    "    return Model(inputs=input, outputs=latent, name=name)\n",
    "\n",
    "#loss\n",
    "cce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False) # sinze labels are not one-hot encoded\n",
    "\n",
    "#optimizer\n",
    "classifier_opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "#construct the network\n",
    "classifier = encoder_network(input_shape, Softmax(), name=\"ConvNet\") #Softmax is for one-hot encoded labels\n",
    "classifier.summary(line_length=133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#training pipeline\n",
    "@tf.function #compiles function, much faster\n",
    "def train_step_classifier(images, labels):\n",
    "    \"\"\"\n",
    "    The training step with the gradient tape (persistent). The switch allows for different training schedules.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as classifier_tape:\n",
    "        pred_class = classifier(images, training=True)\n",
    "        loss = cce_loss(labels, pred_class)\n",
    "\n",
    "    gradients_of_classifier = classifier_tape.gradient(loss, classifier.trainable_variables)\n",
    "    classifier_opt.apply_gradients(zip(gradients_of_classifier, classifier.trainable_variables))\n",
    "\n",
    "@tf.function\n",
    "def generate_and_classify(model, test_input, test_labels):\n",
    "    #notice training is set to false\n",
    "    #this is so all layers run in inference mode (batchnorm)\n",
    "    predictions = model(test_input, training=False)\n",
    "    #sparse for same reason as l\n",
    "    top1 = tf.math.reduce_mean(tf.keras.metrics.sparse_top_k_categorical_accuracy(test_labels, predictions, k=1))\n",
    "    top5 = tf.math.reduce_mean(tf.keras.metrics.sparse_top_k_categorical_accuracy(test_labels, predictions, k=5))\n",
    "    return top1, top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#train\n",
    "def train(epochs):\n",
    "    losses = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print('>>>>>>>>>>>>>. Epoch{}'.format(epoch))\n",
    "        #training\n",
    "        loss = -1\n",
    "        batch_losses = 0\n",
    "        batch_top1 = 0\n",
    "        batch_top5 = 0\n",
    "        count = 0\n",
    "        with tqdm(train_ds, unit=\"batch\") as tepoch:\n",
    "            for image_batch, labels_batch in tepoch:\n",
    "                loss = train_step_classifier(image_batch, labels_batch)\n",
    "                batch_losses += loss\n",
    "                top1, top5 = generate_and_classify(classifier, image_batch, labels_batch)\n",
    "                batch_top1 += top1\n",
    "                batch_top5 += top5\n",
    "                count += 1\n",
    "                tepoch.set_postfix(loss=loss.numpy())\n",
    "        #compute mean losses and accuracies\n",
    "        loss = batch_losses/count\n",
    "        top1 = batch_top1/count\n",
    "        top5 = batch_top5/count\n",
    "\n",
    "        print(f'Loss {loss} (top1 {top1}, top5{top5}')\n",
    "        losses.append(loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_ds = tfds.load('cifar10', split='test', shuffle_files=False, download=True, with_info=False)\n",
    "total_validation_images = info.splits['test'].num_examples\n",
    "print(f\"found {total_validation_images} validation images\")\n",
    "\n",
    "#testing set\n",
    "valid_ds = valid_ds.map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('comp3710')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b95a958677244b4d6bd7f80f106d51a95a8d705e67da7983369de3b3a9efca8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
